{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_trade.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6k5Gw5IVkeHH",
        "QFd9DIiCmNwL",
        "xXy5fczyL0cf"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3vdyOb-kgYI"
      },
      "source": [
        "# IMPORT WHOLE REQUIREMENTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osqTchR6DpuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5053e0a-20ed-4bbb-bccb-33e224b25aa5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        " \n",
        "from datetime import datetime\n",
        "from numpy import genfromtxt\n",
        "from tensorflow import keras\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FpLrinAlauV"
      },
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model\r\n",
        "# https://www.tensorflow.org/tutorials/keras/save_and_load\r\n",
        "# https://www.tensorflow.org/guide/keras/save_and_serialize"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k5Gw5IVkeHH"
      },
      "source": [
        "# TIMER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gxfzj0XD4M1"
      },
      "source": [
        "import time\n",
        "\n",
        "class TimerError(Exception):\n",
        "    \"\"\"A custom exception used to report errors in use of Timer class\"\"\"\n",
        "\n",
        "class Timer:\n",
        "    def __init__(self):\n",
        "        self._start_time = None\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start a new timer\"\"\"\n",
        "        if self._start_time is not None:\n",
        "            raise TimerError(f\"Timer is running. Use .stop() to stop it\")\n",
        "\n",
        "        self._start_time = time.perf_counter()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer, and report the elapsed time\"\"\"\n",
        "        if self._start_time is None:\n",
        "            raise TimerError(f\"Timer is not running. Use .start() to start it\")\n",
        "\n",
        "        elapsed_time = time.perf_counter() - self._start_time\n",
        "        self._start_time = None\n",
        "        print(f\"Executed time: {elapsed_time:0.4f} seconds\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDe0910SkwfF"
      },
      "source": [
        "# Load Data I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nXNaGffEBkV",
        "outputId": "95a2ffd8-b9ff-4df2-80cc-eec409cd72d9"
      },
      "source": [
        "A = np.array([])\n",
        "B = np.array([])\n",
        "\n",
        "# df = genfromtxt('./drive/MyDrive/IPYNB/Datasets/dataset_trade.csv', delimiter=',')\n",
        "df = genfromtxt('./dataset_trade_2k.csv', delimiter=',')\n",
        "print(len(df))\n",
        "for i in range(len(df)):\n",
        "  if(i>1):\n",
        "    A = np.append(A, [ df[i][13], df[i][14], df[i][15], df[i][16], df[i][17] ])\n",
        "    B = np.append(B, [ df[i][23], df[i][24], df[i][25], df[i][26], df[i][27] ])\n",
        "\n",
        "    x_train = np.reshape(A, (-1, 5, ))\n",
        "    y_train = np.reshape(B, (-1, 5, ))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC3lcivE9ToP",
        "outputId": "c86af132-b99b-4c8b-e39d-ececb9d41f22"
      },
      "source": [
        "print(len(x_train))\r\n",
        "print(x_train.shape)\r\n",
        "print(x_train[0])\r\n",
        "\r\n",
        "print(len(y_train))\r\n",
        "print(y_train.shape)\r\n",
        "print(y_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n",
            "(2000, 5)\n",
            "[0.9995052  0.83333333 0.41935484 0.25       0.68333333]\n",
            "2000\n",
            "(2000, 5)\n",
            "[0.96238559 0.96233064 0.9623348  0.96234419 0.1394799 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm02G6jI7_bg",
        "outputId": "ec1f4efd-fa95-42b2-82c8-8eb09e4b2eaf"
      },
      "source": [
        "x_train,\r\n",
        "y_train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.96238559, 0.96233064, 0.9623348 , 0.96234419, 0.1394799 ],\n",
              "       [0.96232033, 0.96227354, 0.96230217, 0.9623034 , 0.15839243],\n",
              "       [0.9622877 , 0.96224907, 0.9622777 , 0.9622463 , 0.08274232],\n",
              "       ...,\n",
              "       [0.95714845, 0.95710195, 0.95699951, 0.95709881, 0.20094563],\n",
              "       [0.95707503, 0.95710195, 0.95708925, 0.95713144, 0.09692671],\n",
              "       [0.95712398, 0.9570938 , 0.95707293, 0.95710696, 0.17730497]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1xUpPZm8OKQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_Train, xTest, y_Train, yTest = train_test_split(x_train, y_train, test_size = 0.01, random_state = 0)\r\n",
        "\r\n",
        "# x_Train, xTest"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7R-xNOUk38-"
      },
      "source": [
        "# DESIGN MODEL DNN ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIIHT-qoLhPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e37126e-1e40-46b9-ff34-8d839324f26a"
      },
      "source": [
        "from keras.layers import *\n",
        "\n",
        "epoch = 1000\n",
        "batch_size = 96\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    Dense(5, input_dim=5),\n",
        "    Flatten(),\n",
        "    Dense(32, activation=tf.nn.leaky_relu),\n",
        "    Dense(32, activation=tf.nn.leaky_relu),\n",
        "    Dense(32, activation=tf.nn.leaky_relu),\n",
        "    Dense(32, activation=tf.nn.leaky_relu),\n",
        "    Dropout(0.8),\n",
        "    Dense(batch_size, activation=tf.nn.leaky_relu),\n",
        "    Dense(batch_size, activation=tf.nn.leaky_relu),\n",
        "    Dense(batch_size, activation=tf.nn.leaky_relu),\n",
        "    Dropout(0.8),\n",
        "    Dense(batch_size, activation=tf.nn.leaky_relu),\n",
        "    Dense(batch_size, activation=tf.nn.leaky_relu),\n",
        "    Dense(batch_size, activation=tf.nn.leaky_relu),\n",
        "    Dropout(0.8),\n",
        "    Dense(32, activation=tf.nn.leaky_relu),\n",
        "    Dense(32, activation=tf.nn.leaky_relu),\n",
        "    Dense(32, activation=tf.nn.leaky_relu),\n",
        "    Dense(32, activation=tf.nn.leaky_relu),\n",
        "    Dropout(0.8),\n",
        "    Dense(5)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam', \n",
        "    loss = 'mse',\n",
        "    metrics = [\n",
        "               'accuracy'\n",
        "    ]\n",
        ")\n",
        "\n",
        "print('Processing...')\n",
        "t = Timer()\n",
        "t.start()\n",
        "train = model.fit(\n",
        "    x_Train,\n",
        "    y_Train,\n",
        "    epochs = epoch,\n",
        "    verbose = 0,\n",
        "    # batch_size = batch_size,\n",
        "    # validation_split = 0.5\n",
        ")\n",
        "t.stop()\n",
        "\n",
        "score = model.evaluate(x_train, y_train)\n",
        "\n",
        "model.save('/model/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZwDodae7ZOK"
      },
      "source": [
        "print(\"Num of Epoch: \", epoch)\r\n",
        "print(\"AVG Training Accuracy\", np.average(train.history['accuracy']))\r\n",
        "print(\"AVG Training Loss\", np.average(train.history['loss']))\r\n",
        "print(\"Data Size: \", sys.getsizeof(df))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFd9DIiCmNwL"
      },
      "source": [
        "# PLOTTING LOSS AND ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT0RJZL-MGMw"
      },
      "source": [
        "e = e = [x / epoch for x in range(epoch)] # [*range(0, epochs, 1)]\n",
        "\n",
        "plt.plot(\n",
        "  e,\n",
        "  train.history['accuracy'],\n",
        "  label='DNN Training Accuracy ({:.4f})'.format(np.average(train.history['accuracy']))\n",
        ")\n",
        "\n",
        "plt.plot(\n",
        "  e,\n",
        "  train.history['loss'],\n",
        "  label='DNN Training Loss ({:.4f})'.format(np.average(train.history['loss']))\n",
        ")\n",
        "plt.xlabel('Iteration Steps')\n",
        "plt.ylabel('Metrics Value')\n",
        "plt.title('DNN Training Accuracy, Loss')\n",
        "plt.legend(loc=4, prop={'size': 8})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXy5fczyL0cf"
      },
      "source": [
        "# Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzbPIqrEL2pi"
      },
      "source": [
        "idx = 20\r\n",
        "\r\n",
        "pred = np.array([\r\n",
        "        x_Train[idx]\r\n",
        "])\r\n",
        "\r\n",
        "#calculating the accuracy from its result \r\n",
        "abs = np.absolute(\r\n",
        "      np.subtract(\r\n",
        "          model.predict(pred)[0],\r\n",
        "          y_Train[idx]\r\n",
        "      )\r\n",
        ")\r\n",
        "loss = np.divide(abs, y_Train[idx])\r\n",
        "acc = np.absolute(\r\n",
        "      np.average(1 - loss)\r\n",
        ")\r\n",
        "\r\n",
        "print('Predictive: ', model.predict(pred)[0])\r\n",
        "print('Target: ', y_Train[idx])\r\n",
        "\r\n",
        "print(\"AVG Testing Accuracy\", acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFavJ8UwMFrU"
      },
      "source": [
        "idx = len(xTest)\r\n",
        "\r\n",
        "plot_target_v1 = np.array([])\r\n",
        "plot_predictive_v1 = np.array([])\r\n",
        "\r\n",
        "for i in range(idx):\r\n",
        "    test = model.predict(np.array([xTest[i]]))[0]\r\n",
        "\r\n",
        "    plot_target_v1 = np.append(plot_target_v1, y_Train[i][0])\r\n",
        "    plot_predictive_v1 = np.append(plot_predictive_v1, test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "259Fv0yyMX9T"
      },
      "source": [
        "e = e = [x / idx for x in range(idx)]\r\n",
        "\r\n",
        "plt.plot(\r\n",
        "  e,\r\n",
        "  plot_target_v1,\r\n",
        "  label='Desired V1'\r\n",
        ")\r\n",
        "\r\n",
        "plt.plot(\r\n",
        "  e,\r\n",
        "  plot_predictive_v1,\r\n",
        "  label='Predictive V1'\r\n",
        ")\r\n",
        "plt.xlabel('Iteration Steps')\r\n",
        "plt.ylabel('Metrics Value')\r\n",
        "plt.title('DNN Testing')\r\n",
        "plt.legend(loc=4, prop={'size': 8})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NylZTb76Pv3V"
      },
      "source": [
        "#@title Select Date\r\n",
        "date_input = '2020-10-13' #@param {type:\"date\"}\r\n",
        "\r\n",
        "slider_hour = 3 #@param {type:\"slider\", min:0, max:24, step:1}\r\n",
        "\r\n",
        "slider_minutes = 48 #@param {type:\"slider\", min:0, max:60, step:1}\r\n",
        "\r\n",
        "print(date_input)\r\n",
        "print(slider_hour)\r\n",
        "print(slider_minutes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8OCtzgEEFOI"
      },
      "source": [
        "#reducing unbalance values\r\n",
        "\r\n",
        "pred = np.array([\r\n",
        "        int(date_input.split('-')[0]) / 2021, \r\n",
        "        int(date_input.split('-')[1]) / 12, \r\n",
        "        int(date_input.split('-')[2]) / 31,\r\n",
        "        slider_hour / 24,\r\n",
        "        slider_minutes / 60\r\n",
        "])\r\n",
        "\r\n",
        "max_v1 = 1.22586 #in csv max_v1\r\n",
        "max_v2 = 1.22593\t\r\n",
        "max_v3 = 1.2258\r\n",
        "max_v4 = 1.22584\t\r\n",
        "max_v5 = 423\r\n",
        "\r\n",
        "\r\n",
        "print(\"Predictive \", pred)\r\n",
        "print(\"Target \", y_Train[10])\r\n",
        "\r\n",
        "# print(\"Predictive V1: \", pred[0] * max_v1)\r\n",
        "# print(\"Predictive V2: \", pred[1] * max_v2)\r\n",
        "# print(\"Predictive V3: \", pred[2] * max_v3)\r\n",
        "# print(\"Predictive V4: \", pred[3] * max_v4)\r\n",
        "# print(\"Predictive V5: \", pred[4] * max_v5)\r\n",
        "\r\n",
        "# print('Target V1: ', y_Train[10][0] * max_v1)\r\n",
        "# print('Target V2: ', y_Train[10][1] * max_v2)\r\n",
        "# print('Target V3: ', y_Train[10][2] * max_v3)\r\n",
        "# print('Target V4: ', y_Train[10][3] * max_v4)\r\n",
        "# print('Target V5: ', y_Train[10][4] * max_v5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}